# **Tokenization with Regular Expressions**

##  Overview
This project demonstrates **text tokenization** using Python's `re` module using words2vec. It includes:
- Downloading a sample text file **the-verdict.txt** from web
- Tokenizing text using regular expressions
- Building a vocabulary and encoding/decoding text
- Implementing a **SimpleTokenizer** class
- Handling **unknown words** and special tokens

##  Features
- **Custom Tokenization** – Uses `re.split()` to split text into words & punctuation  
- **Vocabulary Generation** – Creates a unique mapping of tokens to integers  
- **Encoding & Decoding** – Converts text into numerical tokens and back  
- **Handles Unknown Words** – Uses `<|unk|>` for out-of-vocabulary words  
- **Flexible Implementation** – Includes **two versions** of the tokenizer  


